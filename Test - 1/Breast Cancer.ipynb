{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test - 1 for Machine Learning Algorithms\n",
    "\n",
    "1. Reading Dataset from .csv file\n",
    "2. Data Pre processing (removing unwanted columns, missing values, normalizing data)\n",
    "3. Shaping the mini-datasets\n",
    "4. Splitting the mini-datasets into train and test sets\n",
    "5. Training the model\n",
    "6. Saving the model for future use\n",
    "7. Loading the model from file\n",
    "8. Predicting the test set\n",
    "9. Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from csv file\n",
    "import csv\n",
    "import numpy as np\n",
    "f = open('dataset.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "data = list(reader)\n",
    "f.close()\n",
    "#convert data to numpy array\n",
    "npa = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of rows and columns\n",
    "rows = npa.shape[0]\n",
    "columns = npa.shape[1]\n",
    "print(\"Number of rows:\", rows)\n",
    "print(\"Number of columns:\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing\n",
    "npb = npa[1:,:]\n",
    "header = npa[0,:]\n",
    "npb[npb == '?'] = '0'\n",
    "npb = npb.astype(float)\n",
    "npb[npb == 0] = np.nan\n",
    "res = np.nanmean(npb, axis=0)\n",
    "res = res.astype(int)\n",
    "#replace nan with values from the mean\n",
    "for i in range(columns):\n",
    "    for j in range(rows-1):\n",
    "        if np.isnan(npb[j,i]):\n",
    "            npb[j,i] = res[i]\n",
    "print(header)\n",
    "print(npb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing data into training and testing data\n",
    "#train_x = npb[:350,0:columns-1]\n",
    "#train_y = npb[:350,columns-1]\n",
    "#test_x = npb[350:,0:columns-1]\n",
    "#test_y = npb[350:,columns-1]\n",
    "train_x = list()\n",
    "train_y = list()\n",
    "n_size = 20\n",
    "for i in range((rows//n_size)-1):\n",
    "    train_x.append(npb[i*n_size:i*n_size+n_size,0:columns-1])\n",
    "    train_y.append(npb[i*n_size:i*n_size+n_size,columns-1])\n",
    "test_x = list()\n",
    "test_y = list()\n",
    "for i in range(((rows//n_size)-1),rows//n_size):\n",
    "    test_x.append(npb[i*n_size:i*n_size+n_size,0:columns-1])\n",
    "    test_y.append(npb[i*n_size:i*n_size+n_size,columns-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the data\n",
    "x = 0\n",
    "for i in range(len(train_x)):\n",
    "    x += train_x[i].shape[0]\n",
    "print(\"train_x shape:\", x)\n",
    "x = 0\n",
    "for i in range(len(train_y)):\n",
    "    x += train_y[i].shape[0]\n",
    "print(\"train_y shape:\", x)\n",
    "x = 0\n",
    "for i in range(len(test_x)):\n",
    "    x += test_x[i].shape[0]\n",
    "print(\"test_x shape:\", x)\n",
    "x = 0\n",
    "for i in range(len(test_y)):\n",
    "    x += test_y[i].shape[0]\n",
    "print(\"test_y shape:\", x)\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "#ascending order\n",
    "for i in range(len(train_x)):\n",
    "#descending order\n",
    "#for i in range(len(train_x)-1,-1,-1):\n",
    "    print(\"Training model for fold\", i+1)\n",
    "    model.fit(train_x[i], train_y[i])\n",
    "#model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "import pickle\n",
    "classifier = open('classifier.model', 'wb')\n",
    "pickle.dump(model, classifier)\n",
    "classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading saved model\n",
    "classifier = open('classifier.model', 'rb')\n",
    "model2 = pickle.load(classifier)\n",
    "classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "score = model2.score(test_x[0], test_y[0])\n",
    "print(\"Accuracy:\", score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "928aa7868b69010a68c8c5b7100ff50e2a209a5170144a8178c47f034182c006"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
